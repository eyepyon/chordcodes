# run.py
#!/usr/bin/env python3
"""
ğŸµ MIDI Composer RAG - ãƒ¡ã‚¤ãƒ³ãƒ©ãƒ³ãƒãƒ£ãƒ¼
GPUæœ€é©åŒ–å¯¾å¿œå®Œå…¨ç‰ˆ

ä½¿ç”¨æ–¹æ³•:
  python run.py setup              # ç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
  python run.py train              # ãƒ¢ãƒ‡ãƒ«å­¦ç¿’
  python run.py generate           # éŸ³æ¥½ç”Ÿæˆ
  python run.py web               # Webã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹èµ·å‹•
  python run.py upload            # HuggingFaceã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
  python run.py --help            # ãƒ˜ãƒ«ãƒ—è¡¨ç¤º
"""

import os
import sys
import argparse
import subprocess
import logging
import time
import yaml
import torch
from pathlib import Path
from typing import Dict, Any, Optional, List

# ãƒ­ã‚®ãƒ³ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class MIDIRAGLauncher:
    """MIDI RAG ãƒ¡ã‚¤ãƒ³ãƒ©ãƒ³ãƒãƒ£ãƒ¼"""
    
    def __init__(self):
        self.project_root = Path(__file__).parent
        self.src_path = self.project_root / "src"
        self.config_path = self.project_root / "config"
        
        # ãƒ‘ã‚¹ã‚’è¿½åŠ 
        if str(self.src_path) not in sys.path:
            sys.path.append(str(self.src_path))
    
    def setup_environment(self, gpu: bool = True, profile: str = None):
        """ç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—"""
        logger.info("ğŸ› ï¸ Setting up MIDI RAG environment...")
        
        try:
            # GPUæœ€é©åŒ–è¨­å®šç”Ÿæˆ
            if gpu and torch.cuda.is_available():
                from utils.gpu_optimizer import auto_setup_gpu_config
                
                config_path = self.config_path / f"{profile or 'auto'}_gpu_config.yaml"
                auto_setup_gpu_config(str(config_path))
                logger.info(f"âœ… GPU config created: {config_path}")
                
                # ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±è¡¨ç¤º
                gpu_name = torch.cuda.get_device_name(0)
                gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3
                logger.info(f"ğŸš€ GPU: {gpu_name} ({gpu_memory:.1f}GB)")
            else:
                logger.warning("âš ï¸ GPU not available or disabled")
            
            # å¿…è¦ãªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
            directories = [
                "data/raw/chopin", "data/raw/beethoven", "data/raw/bach", "data/raw/mozart",
                "data/processed", "data/embeddings", "checkpoints", "logs", "output"
            ]
            
            for directory in directories:
                Path(directory).mkdir(parents=True, exist_ok=True)
            
            logger.info("âœ… Environment setup completed!")
            
        except Exception as e:
            logger.error(f"âŒ Environment setup failed: {e}")
            raise
    
    def train_model(self, 
                   config: str = None,
                   epochs: int = 10,
                   gpu: bool = True, 
                   profile: str = None,
                   resume: str = None,
                   wandb: bool = False):
        """ãƒ¢ãƒ‡ãƒ«å­¦ç¿’"""
        logger.info("ğŸ“ Starting model training...")
        
        try:
            # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«
            if not config:
                if gpu and torch.cuda.is_available():
                    config = str(self.config_path / "auto_gpu_config.yaml")
                else:
                    config = str(self.config_path / "config.yaml")
            
            # å­¦ç¿’ã‚¹ã‚¯ãƒªãƒ—ãƒˆå®Ÿè¡Œ
            cmd = [
                sys.executable, 
                str(self.src_path / "train_gpu.py"),
                "--config", config,
                "--epochs", str(epochs)
            ]
            
            if profile:
                cmd.extend(["--profile", profile])
            
            if resume:
                cmd.extend(["--resume", resume])
            
            if wandb:
                cmd.append("--wandb")
            
            # Dry runã‚ªãƒ—ã‚·ãƒ§ãƒ³
            if self._is_dry_run():
                cmd.append("--dry_run")
                logger.info("ğŸ§ª Running in dry-run mode")
            
            logger.info(f"Executing: {' '.join(cmd)}")
            result = subprocess.run(cmd, check=True)
            
            if result.returncode == 0:
                logger.info("ğŸ‰ Training completed successfully!")
            
        except subprocess.CalledProcessError as e:
            logger.error(f"âŒ Training failed with exit code {e.returncode}")
            raise
        except Exception as e:
            logger.error(f"âŒ Training error: {e}")
            raise
    
    def generate_music(self, 
                      prompt: str = None,
                      composer: str = "Chopin",
                      output: str = None,
                      model_path: str = None,
                      interactive: bool = False):
        """éŸ³æ¥½ç”Ÿæˆ"""
        logger.info("ğŸµ Generating music...")
        
        try:
            if interactive:
                # ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãƒ¢ãƒ¼ãƒ‰
                self._interactive_generation()
            else:
                # ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³ç”Ÿæˆ
                if not prompt:
                    prompt = input("Enter generation prompt: ")
                
                if not output:
                    output = f"generated_{composer.lower()}_{int(time.time())}.mid"
                
                if not model_path:
                    model_path = str(Path("checkpoints/best_model.pt"))
                
                # ç”Ÿæˆã‚¹ã‚¯ãƒªãƒ—ãƒˆå®Ÿè¡Œ
                cmd = [
                    sys.executable,
                    str(self.src_path / "generate.py"),
                    "--prompt", prompt,
                    "--composer", composer,
                    "--output", output
                ]
                
                if os.path.exists(model_path):
                    cmd.extend(["--model_path", model_path])
                
                logger.info(f"Executing: {' '.join(cmd)}")
                subprocess.run(cmd, check=True)
                
                logger.info(f"âœ… Music generated: {output}")
        
        except Exception as e:
            logger.error(f"âŒ Generation failed: {e}")
            raise
    
    def _interactive_generation(self):
        """ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ç”Ÿæˆ"""
        print("\\nğŸ¼ Interactive Music Generation")
        print("=" * 50)
        
        while True:
            try:
                print("\\nOptions:")
                print("1. Generate with prompt")
                print("2. Use preset prompt") 
                print("3. Batch generation")
                print("4. Exit")
                
                choice = input("\\nSelect option (1-4): ").strip()
                
                if choice == "1":
                    prompt = input("Enter prompt: ")
                    composer = input("Composer (Chopin/Beethoven/Bach/Mozart): ") or "Chopin"
                    
                    self.generate_music(prompt=prompt, composer=composer)
                
                elif choice == "2":
                    presets = {
                        "1": "Generate a romantic nocturne with expressive melodies",
                        "2": "Create a dramatic sonata movement with powerful themes", 
                        "3": "Compose a baroque fugue with intricate counterpoint",
                        "4": "Write a classical minuet with elegant phrasing"
                    }
                    
                    print("\\nPreset prompts:")
                    for key, value in presets.items():
                        print(f"{key}. {value}")
                    
                    preset_choice = input("Select preset (1-4): ").strip()
                    if preset_choice in presets:
                        prompt = presets[preset_choice]
                        composer = ["Chopin", "Beethoven", "Bach", "Mozart"][int(preset_choice)-1]
                        
                        self.generate_music(prompt=prompt, composer=composer)
                
                elif choice == "3":
                    self._batch_generation()
                
                