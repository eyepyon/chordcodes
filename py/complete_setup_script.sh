#!/bin/bash
#
# ğŸš€ MIDI Composer RAG GPUæœ€é©åŒ– å®Œå…¨ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
# CUDA 12.x å¯¾å¿œç‰ˆ
#

set -e

# ã‚«ãƒ©ãƒ¼å®šç¾©
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
PURPLE='\033[0;35m'
CYAN='\033[0;36m'
NC='\033[0m'

# ãƒãƒŠãƒ¼è¡¨ç¤º
show_banner() {
    echo -e "${CYAN}"
    echo "â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ"
    echo "â–ˆ                                                          â–ˆ"
    echo "â–ˆ        ğŸµ MIDI Composer RAG GPU OPTIMIZER ğŸš€           â–ˆ"
    echo "â–ˆ                                                          â–ˆ"
    echo "â–ˆ     Classical Music AI with CUDA 12 Acceleration        â–ˆ"
    echo "â–ˆ                                                          â–ˆ"
    echo "â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ"
    echo -e "${NC}"
    echo
}

# é€²è¡ŒçŠ¶æ³è¡¨ç¤º
progress_bar() {
    local progress=$1
    local total=100
    local width=50
    local percentage=$((progress * 100 / total))
    local completed=$((progress * width / total))
    local remaining=$((width - completed))
    
    printf "\r${BLUE}Progress: [${GREEN}"
    printf "%*s" $completed | tr ' ' '='
    printf "${YELLOW}"
    printf "%*s" $remaining | tr ' ' '-'
    printf "${BLUE}] ${percentage}%%${NC}"
    
    if [ $progress -eq $total ]; then
        echo
    fi
}

# GPUç’°å¢ƒç¢ºèª
check_gpu_environment() {
    echo -e "${BLUE}ğŸ” GPUç’°å¢ƒã‚’ç¢ºèªä¸­...${NC}"
    
    # NVIDIA GPUç¢ºèª
    if ! command -v nvidia-smi &> /dev/null; then
        echo -e "${RED}âŒ nvidia-smi ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚NVIDIAãƒ‰ãƒ©ã‚¤ãƒãƒ¼ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ãã ã•ã„${NC}"
        exit 1
    fi
    
    # GPUæƒ…å ±è¡¨ç¤º
    echo -e "${PURPLE}æ¤œå‡ºã•ã‚ŒãŸGPU:${NC}"
    nvidia-smi --query-gpu=name,memory.total,compute_cap --format=csv,noheader,nounits
    
    # CUDAç¢ºèª
    if command -v nvcc &> /dev/null; then
        cuda_version=$(nvcc --version | grep "release" | awk '{print $6}' | cut -c2-)
        echo -e "${GREEN}âœ… CUDA Version: $cuda_version${NC}"
        
        if [[ "$cuda_version" =~ ^12\. ]]; then
            echo -e "${GREEN}âœ… CUDA 12.x ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸ${NC}"
        else
            echo -e "${YELLOW}âš ï¸  CUDA 12.xä»¥å¤–ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã§ã™: $cuda_version${NC}"
        fi
    else
        echo -e "${YELLOW}âš ï¸  nvcc ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“${NC}"
    fi
    
    echo
}

# ã‚·ã‚¹ãƒ†ãƒ ä¾å­˜é–¢ä¿‚ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
install_system_dependencies() {
    echo -e "${BLUE}ğŸ“¦ ã‚·ã‚¹ãƒ†ãƒ ä¾å­˜é–¢ä¿‚ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ä¸­...${NC}"
    
    progress_bar 10
    sudo apt update -qq
    
    progress_bar 30
    sudo apt install -y \
        python3 python3-pip python3-venv \
        build-essential cmake pkg-config \
        libasound2-dev jackd2 qjackctl \
        fluidsynth timidity \
        libsndfile1-dev libfftw3-dev portaudio19-dev \
        ffmpeg git wget curl > /dev/null 2>&1
    
    progress_bar 100
    echo -e "${GREEN}âœ… ã‚·ã‚¹ãƒ†ãƒ ä¾å­˜é–¢ä¿‚ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«å®Œäº†${NC}"
}

# Pythonä»®æƒ³ç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
setup_python_env() {
    echo -e "${BLUE}ğŸ Pythonç’°å¢ƒã‚’ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ä¸­...${NC}"
    
    # ä»®æƒ³ç’°å¢ƒä½œæˆ
    if [ ! -d "midi_rag_env" ]; then
        python3 -m venv midi_rag_env
    fi
    
    # ä»®æƒ³ç’°å¢ƒã‚’ã‚¢ã‚¯ãƒ†ã‚£ãƒ™ãƒ¼ãƒˆ
    source midi_rag_env/bin/activate
    
    # pipã‚¢ãƒƒãƒ—ã‚°ãƒ¬ãƒ¼ãƒ‰
    pip install -q --upgrade pip setuptools wheel
    
    echo -e "${GREEN}âœ… Pythonç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—å®Œäº†${NC}"
}

# GPUå¯¾å¿œPythonãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
install_gpu_packages() {
    echo -e "${BLUE}âš¡ GPUå¯¾å¿œãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ä¸­...${NC}"
    
    source midi_rag_env/bin/activate
    
    progress_bar 20
    # PyTorch (CUDA 12.1å¯¾å¿œ)
    pip install -q torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
    
    progress_bar 40
    # GPUæœ€é©åŒ–ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
    pip install -q accelerate bitsandbytes flash-attn faiss-gpu
    
    progress_bar 60
    # éŸ³æ¥½å‡¦ç†ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
    pip install -q pretty-midi music21 mido python-rtmidi librosa madmom
    
    progress_bar 80
    # æ©Ÿæ¢°å­¦ç¿’ãƒ»RAG
    pip install -q transformers sentence-transformers chromadb
    pip install -q numpy pandas scikit-learn matplotlib seaborn
    
    # Web UI
    pip install -q fastapi uvicorn streamlit gradio
    
    # HuggingFace
    pip install -q huggingface_hub safetensors
    
    # GPUç›£è¦–
    pip install -q gpustat py3nvml psutil
    
    # ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
    pip install -q tqdm jupyter python-dotenv pyyaml wandb
    
    progress_bar 100
    echo -e "${GREEN}âœ… GPUå¯¾å¿œãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«å®Œäº†${NC}"
}

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹é€ ä½œæˆ
create_project_structure() {
    echo -e "${BLUE}ğŸ“ ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹é€ ã‚’ä½œæˆä¸­...${NC}"
    
    local project_name="midi_rag_project"
    mkdir -p $project_name
    cd $project_name
    
    # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ ä½œæˆ
    mkdir -p {data/{raw/{chopin,beethoven,bach,mozart},processed,embeddings,models},src/{models/{feature_extraction,embedding,generation},utils,api},config,logs,scripts,output/{generated_midi,audio},cache,checkpoints}
    
    # åŸºæœ¬ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ
    touch requirements.txt README.md .env .gitignore
    touch src/__init__.py src/models/__init__.py src/utils/__init__.py src/api/__init__.py
    
    echo -e "${GREEN}âœ… ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹é€ ä½œæˆå®Œäº†${NC}"
}

# è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ
create_config_files() {
    echo -e "${BLUE}âš™ï¸  è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆä¸­...${NC}"
    
    # ãƒ¡ã‚¤ãƒ³è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«
    cat > config/config.yaml << 'EOF'
# MIDI RAG ã‚·ã‚¹ãƒ†ãƒ è¨­å®š

# ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹è¨­å®š
database:
  chromadb_path: "./data/chromadb"
  collection_name: "midi_composers"

# ç‰¹å¾´é‡è¨­å®š
features:
  embedding_dim: 256
  max_sequence_length: 1024

# ãƒ¢ãƒ‡ãƒ«è¨­å®š
model:
  vocab_size: 512
  hidden_size: 768
  num_attention_heads: 12
  num_hidden_layers: 12
  max_position_embeddings: 2048
  dropout: 0.1

# GPUè¨­å®š
gpu:
  enabled: true
  device: "cuda"
  mixed_precision: true
  compile_model: true

# å­¦ç¿’è¨­å®š
training:
  batch_size: 16
  gradient_accumulation_steps: 4
  learning_rate: 2e-5
  weight_decay: 0.01
  max_grad_norm: 1.0
  warmup_ratio: 0.1
  fp16: true
  gradient_checkpointing: true
  dataloader_num_workers: 4
  pin_memory: true

# ç”Ÿæˆè¨­å®š
generation:
  max_length: 1024
  temperature: 0.8
  top_p: 0.9
  top_k: 50
  use_cache: true

# ç›£è¦–è¨­å®š
monitoring:
  enabled: true
  log_interval: 10
  gpu_stats: true
EOF

    # ç’°å¢ƒå¤‰æ•°è¨­å®š
    cat > .env << 'EOF'
# ç’°å¢ƒå¤‰æ•°è¨­å®š
PYTHONPATH=./src
CUDA_VISIBLE_DEVICES=0
PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:512
HF_HOME=./cache/huggingface
TRANSFORMERS_CACHE=./cache/transformers
TOKENIZERS_PARALLELISM=true
EOF

    # requirements.txt
    cat > requirements.txt << 'EOF'
torch>=2.0.0
torchvision>=0.15.0
torchaudio>=2.0.0
transformers>=4.30.0
accelerate>=0.20.0
bitsandbytes>=0.39.0
flash-attn>=2.0.0
pretty-midi>=0.2.10
music21>=8.1.0
chromadb>=0.4.0
faiss-gpu>=1.7.4
numpy>=1.24.0
pandas>=2.0.0
scikit-learn>=1.3.0
matplotlib>=3.7.0
streamlit>=1.25.0
gradio>=3.40.0
fastapi>=0.100.0
uvicorn>=0.23.0
huggingface_hub>=0.15.0
safetensors>=0.3.0
gpustat>=1.1.0
py3nvml>=0.2.7
psutil>=5.9.0
tqdm>=4.65.0
python-dotenv>=1.0.0
pyyaml>=6.0
wandb>=0.15.0
EOF

    echo -e "${GREEN}âœ… è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆå®Œäº†${NC}"
}

# GPUãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«æ¤œå‡º
detect_gpu_profile() {
    if ! command -v nvidia-smi &> /dev/null; then
        echo "cpu"
        return
    fi
    
    local gpu_memory=$(nvidia-smi --query-gpu=memory.total --format=csv,noheader,nounits | head -1)
    local gpu_name=$(nvidia-smi --query-gpu=name --format=csv,noheader | head -1 | tr '[:upper:]' '[:lower:]')
    
    if [[ "$gpu_name" =~ (a100|h100) ]]; then
        echo "enterprise"
    elif [[ $gpu_memory -gt 20000 ]]; then
        echo "high_end"
    elif [[ $gpu_memory -gt 12000 ]]; then
        echo "mainstream"
    elif [[ $gpu_memory -gt 8000 ]]; then
        echo "budget"
    else
        echo "low_memory"
    fi
}

# ã‚·ã‚¹ãƒ†ãƒ ãƒ†ã‚¹ãƒˆ
run_system_tests() {
    echo -e "${BLUE}ğŸ§ª ã‚·ã‚¹ãƒ†ãƒ ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œä¸­...${NC}"
    
    source midi_rag_env/bin/activate
    
    # PyTorchãƒ†ã‚¹ãƒˆ
    python3 -c "
import torch
print(f'âœ… PyTorch: {torch.__version__}')
print(f'âœ… CUDA Available: {torch.cuda.is_available()}')
if torch.cuda.is_available():
    print(f'âœ… GPU: {torch.cuda.get_device_name(0)}')
    print(f'âœ… GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f}GB')
"
    
    # ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãƒ†ã‚¹ãƒˆ
    python3 -c "
try:
    import transformers, accelerate
    import pretty_midi, music21, chromadb
    import streamlit, gradio, fastapi
    print('âœ… All required packages imported successfully')
except ImportError as e:
    print(f'âŒ Import error: {e}')
    exit(1)
"
    
    echo -e "${GREEN}âœ… ã‚·ã‚¹ãƒ†ãƒ ãƒ†ã‚¹ãƒˆå®Œäº†${NC}"
}

# ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°
main() {
    show_banner
    
    # å¼•æ•°è§£æ
    SETUP_MODE="full"
    
    case "${1:-}" in
        --full)
            SETUP_MODE="full"
            ;;
        --quick)
            SETUP_MODE="quick"
            ;;
        --help|-h)
            echo "Usage: $0 [--full|--quick|--help]"
            echo "  --full   Complete setup with all dependencies"
            echo "  --quick  Quick setup with minimal dependencies"
            echo "  --help   Show this help message"
            exit 0
            ;;
    esac
    
    check_gpu_environment
    
    local gpu_profile=$(detect_gpu_profile)
    echo -e "${PURPLE}ğŸ¯ Detected GPU profile: ${gpu_profile}${NC}"
    
    # å®Ÿè¡Œç¢ºèª
    echo -e "${YELLOW}Setup mode: ${SETUP_MODE}${NC}"
    echo
    read -p "Continue with GPU-optimized setup? (y/N): " -n 1 -r
    echo
    if [[ ! $REPLY =~ ^[Yy]$ ]]; then
        echo "Setup cancelled."
        exit 0
    fi
    
    echo -e "\n${CYAN}ğŸš€ Starting GPU-optimized MIDI RAG setup...${NC}\n"
    
    # ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—å®Ÿè¡Œ
    case $SETUP_MODE in
        "full")
            install_system_dependencies
            setup_python_env
            install_gpu_packages
            create_project_structure
            create_config_files
            run_system_tests
            ;;
        "quick")
            setup_python_env
            install_gpu_packages
            create_project_structure
            create_config_files
            ;;
    esac
    
    # å®Œäº†ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
    echo -e "\n${GREEN}ğŸ‰ GPU-optimized MIDI Composer RAG setup completed!${NC}\n"
    
    echo -e "${CYAN}Quick Start Commands:${NC}"
    echo "ğŸ“ cd midi_rag_project"
    echo "ğŸ”‹ source ../midi_rag_env/bin/activate"
    echo "ğŸŒ streamlit run src/api/web_interface.py"
    echo
    
    echo -e "${YELLOW}Next Steps:${NC}"
    echo "1. Place MIDI files in data/raw/{composer}/ directories"
    echo "2. Set HuggingFace token: export HF_TOKEN='your_token'"
    echo "3. Run training or use the web interface"
    echo
}

# ã‚¹ã‚¯ãƒªãƒ—ãƒˆå®Ÿè¡Œ
if [[ "${BASH_SOURCE[0]}" == "${0}" ]]; then
    main "$@"
fi